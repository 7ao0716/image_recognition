# -*- coding: utf-8 -*-
"""顔画像認識30.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19OEymr_Bk4xbMIC-ZnWFiTm2yFGoaCwL
"""

#Kerasインポート
import keras
import random
from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D
from keras.layers import Activation,Dropout,Flatten,Dense,BatchNormalization
from keras.utils import np_utils
import numpy as np
import os,glob
import numpy as np
from PIL import Image

#データの保存場所のパスを設定
'''
base_dir = "./facedata_30/"

train_dir = os.path.join(base_dir, 'train')
test_dir = os.path.join(base_dir, 'test')
train_man = os.path.join(train_dir, '/man')
test_man = os.path.join(test_dir, '/man')
train_woman = os.path.join(train_dir, 'woman')
test_woman = os.path.join(test_dir, 'woman')
dir_list = [train_dir, test_dir, train_man, test_man, train_woman, test_woman]
'''
org_man_dir = '/content/drive/MyDrive/facedata_30/man/'
org_woman_dir = '/content/drive/MyDrive/facedata_30/woman/'
man_faces = os.listdir(org_man_dir)
woman_faces = os.listdir(org_woman_dir)

classes = ["man","woman"]
num_classes = len(classes)
image_size = 200
num_testdata = 300
 
#データの箱準備
X_train = []
X_test = []
Y_train = []
Y_test = []

'''
#データの水増し

#男性女性のデータを選択するパート
for index, classlabel in enumerate(classes):
    photos_dir = "/content/drive/MyDrive/facedata_30/" + classlabel
    files = glob.glob(photos_dir+"/*.jpg")
    random.shuffle(files)
    #print(files)
 
#画像データを50×50のnumpy形式に変換
    for i, file in enumerate(files):
        if i > 1000:
          break
        image = Image.open(file)
        image = image.convert("RGB")
        image = image.resize((image_size,image_size))
        data = np.asarray(image)
        
#50枚をテストデータにする
        if i < num_testdata:
            X_test.append(data)
            Y_test.append(index)
            
        else:
            X_train.append(data)
            Y_train.append(index)

print(len(X_train))
print(len(Y_train))
X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(Y_train)
y_test = np.array(Y_test)
'''
#分割したデータを保存
xy = np.load("/content/face_aug_30_2.npy", allow_pickle=True)
X_train,X_test,y_train,y_test = xy
#xy = (X_train,X_test,y_train,y_test)
#np.save("./face_aug_30_2.npy",xy)

print(X_train.shape)
print(y_train.shape)
#データの正規化、カテゴリカル化
X_train = X_train.astype("float")/256
X_test = X_test.astype("float")/256
y_train = np_utils.to_categorical(y_train, num_classes)
y_test = np_utils.to_categorical(y_test,num_classes)

print(y_train.shape)
#モデル2　ドロップアウト層、L2正則化項の追加
from keras import regularizers

#モデル1
model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape = X_train.shape[1:]))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))#Doropout層追加
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.25))#Doropout層追加
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128,kernel_regularizer=regularizers.l2(0.0001), activation='relu'))#L2正則化項追加
model.add(Dropout(0.5))#Doropout引数変更
model.add(Dense(num_classes, activation='softmax'))

#モデル2コンパイル
model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])

#学習を開始
hist = model.fit(X_train, y_train,batch_size=128,epochs=30,validation_split=0.1,verbose=1)

#スコア
scores = model.evaluate(X_test, y_test)
print('loss = {:.4} '.format(scores[0]))
print('accuracy = {:.4%} '.format(scores[1]))

